---
layout:     post
title:      Hadoop环境搭建
subtitle:   使用Docker
date:       2021-09-29
author:     AnAn
header-img: https://dss2.bdstatic.com/kfoZeXSm1A5BphGlnYG/skin/113.jpg
catalog: true
tags:
    - 运维
    - 分布式
---
##介绍
使用群晖Docker 搭建hadoop分布式服务
使用了4个jdk1.8的容器分别作1个nameNode 和3个dataNode
命名分别为：
```text
hdfs-master
hdfs-slave1
hdfs-slave2
hdfs-slave3
```
##目录
-[常见问题](#id000)
- [环境配置](#id001)
  - [拉取JDK1.8镜象](#id001)
  - [配置ssh server](#id002)
  - [配置sshd自启动](#id003)
  - [ssh免密登陆](#id004)
  - [添加环境变量](#id004)
- [hadoop配置](#id005)
  - [core-site.xml配置](#id006)
  - [hdfs-site.xml配置](#id007)
  - [mapred-site.xml配置](#id008)
  - [yarn-site.xml配置](#id009)
  - [workers配置](#id010)
  - [hadoop-env.xml配置](#id011)
  - [从节点配置](#id013)
  - [格式化hdfs](#id012)
  - [hdfs的运行](#id012)
## [常见问题]
<a name="id000"></a>
- 启动问题 可以如下命令查看具体错误
```shell script
hdfs dfsadmin -report
```   
- hdfs种的主机名中不要出现下划线(_),可以使用“-”代替。

## 环境配置
<a name="id001"></a>
####拉取JDK1.8镜象
- 本例使用的镜像地址为：dustheart/jdk1.8_8u261:v8u261 ,镜像为精简版centos系统
```shell script
docker pull dustheart/jdk1.8_8u261:v8u261
```
<a name="id002"></a>
#### 配置ssh server
- 下载安装ssh server 和 ssh client
```shell script
yum install openssh-server -y
yum install openssh-clients -y
```
  <a name="id003"></a>
#### 配置ssh server自启动
- 拉取的centos镜像没有systemd工具，这里使用修改/etc/bashrc的方式来自启动，实验发现修改/etc/profile无法自动执行启动脚本
- 启动脚本如下,文件路径为/usr/bin/sshd_autorun.sh
```shell script
#!/bin/bash
sshd_flag=`ps -ef|grep sshd |grep -v grep`
if [ ${#sshd_flag} == 0 ]
then
/usr/sbin/sshd -D
fi
```
- 将 “/usr/bin/sshd_autorun.sh”添加到/etc/bashrc文件末尾
- ssh server 启动应该会报错，需要修复以下
```shell script
ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key
ssh-keygen -t rsa -f /etc/ssh/ssh_host_ecdsa_key
ssh-keygen -t rsa -f /etc/ssh/ssh_host_ed25519_key
```
  <a name="id004"></a>
#### ssh免密登陆
- 4个容器需要启动ssh-server
```shell script
ssh-kengen -t rsa #一路下一步
ssh-copy-id hdfs-master #自己需要给自己拷贝一份
ssh-copy-id hdfs-slave1 #docker可以自动将dockerName映射为ip
ssh-copy-id hdfs-slave2
ssh-copy-id hdfs-slave3
```
    <a name="id004"></a>
#### 添加环境变量
- /etc/bashrc中添加如下，/hadoop/hadoop-3.3.1/为haddop解压路径
```shell script
export PATH=/hadoop/hadoop-3.3.1/bin:/hadoop/hadoop-3.3.1/sbin:$PATH
```
## hadoop配置
  <a name="id005"></a>
#### core-site.xml配置
  <a name="id006"></a>
- 配置
```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>   #默认
        <value>hdfs://hdfs-master:9000</value> #hdfs的api接口
    </property>
    <property>
        <name>hadoop.tmp.dir</name> #hadoop运行时产生临时数据的存储目录
        <value>/home/hadoop/apps/tmp</value> #该目录的地址
    </property>
</configuration>
```
#### hdfs-site.xml配置
  <a name="id007"></a>
- vi /hadoop/hadoop-3.3.1/etc/hadoop/hdfs-site.xml
```xml
<configuration>
        <property>
                <name>dfs.namenode.secondary.http-address</name>
                <value>hdfs-master:50090</value>
        </property>
        <property>
                <name>dfs.replication</name> #设置副本个数
                <value>3</value>
        </property>
        <property>
                <name>dfs.namenode.name.dir</name> #设置namende数据存放点
                <value>/home/hadoop/apps/dfs/name</value>
        </property>
        <property>
                <name>dfs.datanode.data.dir</name> #设置datanode数据存放点
                <value>/home/hadoop/apps/dfs/data</value>
        </property>
</configuration>
```
#### mapred-site.xml配置
  <a name="id008"></a>
- vi /hadoop/hadoop-3.3.1/etc/hadoop/mapred-site.xml
```xml
<configuration>
    <property>
        <name>mapreduce.framwork.name</name>    #设置mapreduce的运行平台的名称
        <value>yarn</value> #设置mapreduce的运行平台为yarn
    </property>
</configuration>
```
#### yarn-site.xml配置
  <a name="id009"></a>
- vi /hadoop/hadoop-3.3.1/etc/hadoop/yarn-site.xml
```xml
<configuration>
    <property>
        <name>yarn.resourcemanager.hostname</name> #指定yarn的老大的地址
        <value>hdfs-master</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>  #reducer获取数据的方式
        <value>mapreduce_shuffle</value> 
    </property>
</configuration>
```
#### workers配置
  <a name="id010"></a>
- vi /hadoop/hadoop-3.3.1/etc/hadoop/workers
- 添加
```text
hdfs-slave1
hdfs-slave2
hdfs-slave3
```
#### hadoop-env.xml配置
  <a name="id011"></a>
- vi /hadoop/hadoop-3.3.1/etc/hadoop/hadoop-env.sh
- 添加root启动，配置JAVA_HOME
```shell script
export HDFS_DATANODE_USER=root                                                                                                        
export HDFS_DATABODE_SECURE_USER=root                                                                                                 
export HDFS_NAMENODE_USER=root                                                                                                        
export HDFS_SECONDARYNAMENODE_USER=root                                                                                               
export YARN_RESOURCEMANAGER_USER=root                                                                                                 
export YARN_NODEMANAGER_USER=root

export JAVA_HOME=/usr/local/jdk/jdk1.8.0_261
```
#### 从节点配置
  <a name="id014"></a>
- 如下为全量复制，比较慢，可以采用解压缩包，然后值复制哦诶值文件的方法
```shell script
scp -r /hadoop/hadoop3.3.1 hdfs-slave1:/hadoop/
scp -r /hadoop/hadoop3.3.1 hdfs-slave2:/hadoop/
scp -r /hadoop/hadoop3.3.1 hdfs-slave3:/hadoop/
```
#### 格式化hdfs
  <a name="id013"></a>
```shell script
hdfs namenode -format
```
#### hdfs的运行
  <a name="id013"></a>
- 启动hdfs
```shell script
start-dfs.sh
```
- 停止hdfs
```shell script
stop-dfs.sh
```
- 在线监控
```shell script
http://hdfs-master:9870
#可以使用docker配置端口映射,直接用宿主机地址访问
```